import requests
import pandas as pd
import psycopg2
from psycopg2.extras import execute_values
import time
import uuid
from datetime import datetime
from utils import load_env, create_connection, get_company_tickers, get_date_uuids, get_acc_ids, to_numeric_safe
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ğŸ”‘ API Key
API_KEY = "58d6b02297b245067c9e7d9f1a32639ca1140072"  # ì‹¤ì œ API í‚¤ë¡œ êµì²´

# ë³´ê³ ì„œ ì½”ë“œ
REPORT_CODES = {
    "q1": "11013",
    "semi": "11012",
    "q3": "11014",
    "annual": "11011"
}

FS_PRIORITY = ["CFS", "OFS"]

def get_latest_date(conn, ticker, report_code):
    logger.info("í‹°ì»¤ %s, ë³´ê³ ì„œ %sì˜ ìµœì‹  ë°ì´í„° ë‚ ì§œ ì¡°íšŒ ì‹œì‘", ticker, report_code)
    cursor = conn.cursor()
    query = """
    SELECT MAX(d.date)
    FROM account_raw_data ard
    JOIN date d ON ard.date_id = d.date_id
    WHERE ard.ticker = %s AND ard.report_code = %s
    """
    cursor.execute(query, (ticker, report_code))
    result = cursor.fetchone()
    cursor.close()
    if result[0]:
        logger.info("í‹°ì»¤ %s, ë³´ê³ ì„œ %sì˜ ìµœì‹  ë‚ ì§œ: %s", ticker, report_code, result[0])
        return result[0].year
    logger.info("í‹°ì»¤ %s, ë³´ê³ ì„œ %sì— ê¸°ì¡´ ë°ì´í„° ì—†ìŒ, ê¸°ë³¸ ì—°ë„ ì‚¬ìš©", ticker, report_code)
    return 2024

def fetch_financial_data(corp_code, year, reprt_code):
    logger.info("í‹°ì»¤ %s, ì—°ë„ %s, ë³´ê³ ì„œ %s ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘", corp_code, year, reprt_code)
    corp_code = str(corp_code).zfill(8)
    for fs_div in FS_PRIORITY:
        url = "https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json"
        params = {
            "crtfc_key": API_KEY,
            "corp_code": corp_code,
            "bsns_year": year,
            "reprt_code": reprt_code,
            "fs_div": fs_div
        }
        try:
            response = requests.get(url, params=params)
            data = response.json()
            if data.get("status") == "000" and data.get("list"):
                logger.info("í‹°ì»¤ %s, ì—°ë„ %s, ë³´ê³ ì„œ %s, %s ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: %d í–‰", corp_code, year, reprt_code, fs_div, len(data["list"]))
                return data["list"]
            elif data.get("status") == "013":
                logger.warning("í‹°ì»¤ %s, ì—°ë„ %s, ë³´ê³ ì„œ %s, %s ë°ì´í„° ì—†ìŒ", corp_code, year, reprt_code, fs_div)
                continue
        except Exception as e:
            logger.error("í‹°ì»¤ %s, ì—°ë„ %s, ë³´ê³ ì„œ %s ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: %s", corp_code, year, reprt_code, e)
    return []

def download_and_reshape_data(ticker, corp_code, corp_name, year, reprt_code):
    logger.info("í‹°ì»¤ %s ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: ì—°ë„ %s, ë³´ê³ ì„œ %s", ticker, year, reprt_code)
    response = fetch_financial_data(corp_code, year, reprt_code)
    if not response:
        logger.warning("í‹°ì»¤ %sì— ëŒ€í•œ ë°ì´í„° ì—†ìŒ: ì—°ë„ %s, ë³´ê³ ì„œ %s", ticker, year, reprt_code)
        return None

    # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
    data = []
    for item in response:
        row = {
            "date": item.get("thstrm_dt"),  # ì¬ë¬´ì œí‘œ ê¸°ì¤€ ë‚ ì§œ
            "ticker": ticker,
            "report_code": reprt_code,
            "data_type": item.get("account_nm"),
            "value": to_numeric_safe(item.get("thstrm_amount")),
            "currency": item.get("currency")
        }
        data.append(row)
    
    df = pd.DataFrame(data)
    logger.info("í‹°ì»¤ %s ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: %d í–‰", ticker, len(df))
    # ë””ë²„ê¹…: ë°ì´í„° í™•ì¸
    if df['value'].isna().all():
        logger.warning("í‹°ì»¤ %sì˜ ëª¨ë“  value ê°’ì´ NaNì…ë‹ˆë‹¤.", ticker)
    return df[['date', 'ticker', 'report_code', 'data_type', 'value', 'currency']]

def map_data_to_ids(data_df, date_map, acc_map):
    logger.info("ë°ì´í„°í”„ë ˆì„ ID ë§¤í•‘ ì‹œì‘")
    try:
        # date ì—´ì„ date_idë¡œ ë³€í™˜
        data_df['date_id'] = data_df['date'].map(lambda x: date_map.get(x.replace(".", "-") if isinstance(x, str) else x.strftime('%Y-%m-%d') if hasattr(x, 'strftime') else x))
        # data_type ì—´ì„ acc_idë¡œ ë³€í™˜
        data_df['acc_id'] = data_df['data_type'].map(lambda x: acc_map.get(x))
        # ìœ íš¨í•˜ì§€ ì•Šì€ date_id ë˜ëŠ” acc_idëŠ” ì œì™¸
        original_len = len(data_df)
        data_df = data_df.dropna subset=['date_id', 'acc_id'])
        logger.info(" ë°ì´í„°í”„ë ˆì„ ID ë§¤í•‘ ì™„ë£Œ: %d/%d í–‰ ìœ ì§€", len(data_df), original_len)
        if original_len > len(data_df):
            logger.warning("date_id ë˜ëŠ” acc_id ëˆ„ë½ìœ¼ë¡œ ì¸í•´ %d í–‰ ì œì™¸", original_len - len(data_df))
        return data_df[['date_id', 'ticker', 'report_code', 'acc_id', 'value', 'currency']]
    except Exception as e:
        logger.error("ë°ì´í„°í”„ë ˆì„ ID ë§¤í•‘ ì˜¤ë¥˜: %s", e)
        return None

def insert_financial_data(conn, ticker, data_df):
    logger.info("í‹°ì»¤ %s ë°ì´í„° ì‚½ì… ì‹œì‘", ticker)
    cursor = conn.cursor()
    try:
        batch_data = []
        for _, row in data_df.iterrows():
            value = float(row['value']) if pd.notna(row['value']) else None
            batch_data.append((
                str(uuid.uuid4()),  # acc_raw_id
                row['date_id'],
                row['ticker'],
                row['report_code'],
                row['acc_id'],
                value,
                row['currency']
            ))

        if batch_data:
            cursor.executemany(
                """
                INSERT INTO account_raw_data (acc_raw_id, date_id, ticker, report_code, acc_id, acc_raw_data, currency)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT DO NOTHING;
                """,
                batch_data
            )
            conn.commit()
            logger.info("í‹°ì»¤ %s ë°ì´í„° ì‚½ì… ì™„ë£Œ: %d í–‰", ticker, len(batch_data))
        else:
            logger.warning("í‹°ì»¤ %sì— ì‚½ì…í•  ë°ì´í„° ì—†ìŒ", ticker)
    except Exception as e:
        conn.rollback()
        logger.error("í‹°ì»¤ %s ë°ì´í„° ì‚½ì… ì˜¤ë¥˜: %s", ticker, e)
    finally:
        cursor.close()

def main():
    logger.info("í”„ë¡œê·¸ë¨ ì‹œì‘")
    base_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.abspath(os.path.join(base_dir, os.pardir))
    local_env_path = os.path.join(parent_dir, '.env.local')

    # ë‹¨ê³„ 1: í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    logger.info("ë‹¨ê³„ 1: í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ")
    env_config = load_env(local_env_path)

    # ë‹¨ê³„ 2: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    logger.info("ë‹¨ê³„ 2: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°")
    conn = create_connection(env_config)

    # ë‹¨ê³„ 3: ë°ì´í„° ì¡°íšŒ (í‹°ì»¤, ê³„ì • ID)
    logger.info("ë‹¨ê³„ 3: ë°ì´í„° ì¡°íšŒ")
    tickers = get_company_tickers(conn)
    acc_names = ['ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ìì‚°ì´ê³„', 'ë¶€ì±„ì´ê³„', 'ìë³¸ì´ê³„']  # ì˜ˆì‹œ ê³„ì •ëª…
    acc_map = get_acc_ids(conn, acc_names)

    # ë‹¨ê³„ 4: ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì¬êµ¬ì„±
    logger.info("ë‹¨ê³„ 4: ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì¬êµ¬ì„±")
    ticker_data = {}
    for i, (ticker, corp_code, corp_name) in enumerate(tickers, 1):
        for report_name, reprt_code in REPORT_CODES.items():
            year = get_latest_date(conn, ticker, reprt_code)
            logger.info("í‹°ì»¤ %d/%d ë‹¤ìš´ë¡œë“œ ì‹œì‘: %s, ì—°ë„ %s, ë³´ê³ ì„œ %s", i, len(tickers), ticker, year, report_name)
            data_df = download_and_reshape_data(ticker, corp_code, corp_name, year, reprt_code)
            if data_df is not None:
                ticker_data[(ticker, reprt_code)] = data_df
            logger.info("í‹°ì»¤ %d/%d ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: %s, ë³´ê³ ì„œ %s", i, len(tickers), ticker, report_name)

    # ë‹¨ê³„ 5: ë‚ ì§œ UUID ì¡°íšŒ ë° ID ë§¤í•‘
    logger.info("ë‹¨ê³„ 5: ë‚ ì§œ UUID ì¡°íšŒ ë° ID ë§¤í•‘")
    all_dates = set()
    for (ticker, _), data_df in ticker_data.items():
        dates = data_df['date'].apply(lambda x: x.replace(".", "-") if isinstance(x, str) else x.strftime('%Y-%m-%d') if hasattr(x, 'strftime') else x)
        all_dates.update(dates)
    date_map = get_date_uuids(conn, list(all_dates))

    mapped_data = {}
    for i, ((ticker, reprt_code), data_df) in enumerate(ticker_data.items(), 1):
        logger.info("í‹°ì»¤ %d/%d ID ë§¤í•‘ ì‹œì‘: %s, ë³´ê³ ì„œ %s", i, len(ticker_data), ticker, reprt_code)
        mapped_df = map_data_to_ids(data_df, date_map, acc_map)
        if mapped_df is not None:
            mapped_data[(ticker, reprt_code)] = mapped_df
        logger.info("í‹°ì»¤ %d/%d ID ë§¤í•‘ ì™„ë£Œ: %s, ë³´ê³ ì„œ %s", i, len(ticker_data), ticker, reprt_code)

    # ë‹¨ê³„ 6: ë°ì´í„° ì‚½ì…
    logger.info("ë‹¨ê³„ 6: ë°ì´í„° ì‚½ì…")
    start_time = time.time()
    for i, ((ticker, reprt_code), data_df) in enumerate(mapped_data.items(), 1):
        logger.info("í‹°ì»¤ %d/%d ì‚½ì… ì‹œì‘: %s, ë³´ê³ ì„œ %s", i, len(mapped_data), ticker, reprt_code)
        insert_financial_data(conn, ticker, data_df)
        logger.info("í‹°ì»¤ %d/%d ì‚½ì… ì™„ë£Œ: %s, ë³´ê³ ì„œ %s", i, len(mapped_data), ticker, reprt_code)

    end_time = time.time()
    logger.info("ì´ ì²˜ë¦¬ ì‹œê°„: %.2f ì´ˆ", end_time - start_time)
    logger.info("í”„ë¡œê·¸ë¨ ì¢…ë£Œ")

    conn.close()

if __name__ == "__main__":
    main()